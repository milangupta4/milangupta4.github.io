---
layout: post
title:  "How the AI Agents landscape is looking, in February 2025"
date:   2025-02-01 11:32:01 +0530
published_date:   2025-02-07 11:32:01 +0530
categories: product
post_id: 46
custom_excerpt: "A look at the AI Agents landscape in February 2025"
subtitle: "A look at the AI Agents landscape in February 2025"
---

LLMs Meet APIs.

That's my understanding of what an AI Agent is.

So, why can't a single LLM do everything? Why doesn't ChatGPT come in and destroy the entire SaaS landscape?

One of the fundamental principles of prompt engineering is that chained prompts are more powerful than a single prompt. 

And, a lot of those specific jobs needs to be on specific data. 

For example a Cloud incident detection platform will be combing through specific logs on Cloud services such as AWS, Azure or GCP ChatGPT is not specificallydesigned for reading logs

With Agentic workflows, you can create workflows by leveraging distinct GPTs.

## Different agents give different formats

Another principle to prompt engineering is that specifying formats for your LLMs gives you more control over the output.

## Orchestration frameworks

Langchain is the most popular orchestration framework.

## LLMs

Deepseek, Anthropic, Google, and OpenAI are the most popular LLMs.